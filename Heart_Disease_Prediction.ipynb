{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf49c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5941d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Heart_Disease_Prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cbde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae94197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8fdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e252ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9656bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6550060",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,15))\n",
    "ax = fig.gca()\n",
    "g = df.hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.countplot(x='Heart Disease', data=df)\n",
    "plt.xlabel('Heart Disease')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f99f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting correlated features using Heatmap\n",
    "\n",
    "# Get correlation of all the features of the dataset\n",
    "corr_matrix = df.corr()\n",
    "top_corr_features = corr_matrix.index\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(data=df[top_corr_features].corr(), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(df, columns=['Sex', 'Chest pain type', 'FBS over 120', 'EKG results', 'Exercise angina', 'Slope of ST', 'Number of vessels fluro', 'Thallium'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standScaler = StandardScaler()\n",
    "columns_to_scale = ['Age', 'BP', 'Cholesterol', 'Max HR', 'ST depression']\n",
    "dataset[columns_to_scale] = standScaler.fit_transform(dataset[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b370dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into dependent and independent features\n",
    "X = dataset.drop('Heart Disease', axis=1)\n",
    "y = dataset['Heart Disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce92192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL BUILDING - 3 Algorithms\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd613b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfdcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-NEIGHBOURS CLASSIFIER\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best accuracy for knn algorithm using cross_val_score \n",
    "knn_scores = []\n",
    "for i in range(1, 21):\n",
    "  knn_classifier = KNeighborsClassifier(n_neighbors=i)\n",
    "  cvs_scores = cross_val_score(knn_classifier, X, y, cv=10)\n",
    "  knn_scores.append(round(cvs_scores.mean(),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results of knn_scores\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot([k for k in range(1, 21)], knn_scores, color = 'orange')\n",
    "for i in range(1,21):\n",
    "    plt.text(i, knn_scores[i-1], (i, knn_scores[i-1]))\n",
    "plt.xticks([i for i in range(1, 21)])\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('K Neighbors Classifier scores for different K values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cbcdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the knn classifier model with k value as 12\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=12)\n",
    "cvs_scores = cross_val_score(knn_classifier, X, y, cv=10)\n",
    "res1=round(cvs_scores.mean(),4)*100\n",
    "print(\"KNeighbours Classifier Accuracy with K=12 is: {}%\".format(res1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fecb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISON TREE CLASSIFIER\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best accuracy for decision tree algorithm using cross_val_score \n",
    "decision_scores = []\n",
    "for i in range(1, 11):\n",
    "  decision_classifier = DecisionTreeClassifier(max_depth=i)\n",
    "  cvs_scores = cross_val_score(decision_classifier, X, y, cv=10)\n",
    "  decision_scores.append(round(cvs_scores.mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bf54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results of decision_scores\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot([i for i in range(1, 11)], decision_scores, color = 'green')\n",
    "for i in range(1,11):\n",
    "    plt.text(i, decision_scores[i-1], (i, decision_scores[i-1]))\n",
    "plt.xticks([i for i in range(1, 11)])\n",
    "plt.xlabel('Depth of Decision Tree (N)')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Decision Tree Classifier scores for different depth values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28475a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the decision tree classifier model with max_depth value as 3\n",
    "decision_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "cvs_scores = cross_val_score(decision_classifier, X, y, cv=10)\n",
    "res2=(round(cvs_scores.mean(), 4)*100)\n",
    "print(\"Decision Tree Classifier Accuracy with max_depth=3 is: {}%\".format(res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST CLASSIFIER\n",
    "# Importing essential libraries\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best accuracy for random forest algorithm using cross_val_score \n",
    "forest_scores = []\n",
    "for i in range(10, 101, 10):\n",
    "  forest_classifier = RandomForestClassifier(n_estimators=i)\n",
    "  cvs_scores = cross_val_score(forest_classifier, X, y, cv=5)\n",
    "  forest_scores.append(round(cvs_scores.mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results of forest_scores\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot([n for n in range(10, 101, 10)], forest_scores, color = 'turquoise')\n",
    "for i in range(1,11):\n",
    "    plt.text(i*10, forest_scores[i-1], (i*10, forest_scores[i-1]))\n",
    "plt.xticks([i for i in range(10, 101, 10)])\n",
    "plt.xlabel('Number of Estimators (N)')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Random Forest Classifier scores for different N values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the random forest classifier model with n value as 90\n",
    "forest_classifier = RandomForestClassifier(n_estimators=90)\n",
    "cvs_scores = cross_val_score(forest_classifier, X, y, cv=5)\n",
    "res3=(round(cvs_scores.mean(), 4)*100)\n",
    "print(\"Random Forest Classifier Accuracy with n_estimators=90 is: {}%\".format(res3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6886902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "from sklearn.svm import SVC\n",
    "# Finding the best accuracy for SVC algorithm using cross_val_score \n",
    "sv_scores = []\n",
    "for i in range(10, 101, 10):\n",
    "  sv_classifier = SVC(kernel='linear', C=1.0)\n",
    "  cvs_scores = cross_val_score(sv_classifier, X, y, cv=5)\n",
    "  sv_scores.append(round(cvs_scores.mean(),3))\n",
    "# Plotting the results of svm_scores\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot([n for n in range(10, 101, 10)], sv_scores, color = 'red')\n",
    "for i in range(1,11):\n",
    "    plt.text(i*10, sv_scores[i-1], (i*10, sv_scores[i-1]))\n",
    "plt.xticks([i for i in range(10, 101, 10)])\n",
    "plt.xlabel('Linear Kernel')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('SVM Classifier scores for different N values')\n",
    "# Training the SVM classifier model with n value as 90\n",
    "sv_classifier = SVC(kernel='linear', C=1.0)\n",
    "cvs_scores = cross_val_score(sv_classifier, X, y, cv=5)\n",
    "print(\"Support Vector Machine Accuracy with linear kernel is: {}%\".format(round(cvs_scores.mean(), 4)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af25fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Finding the best accuracy for LogisticRegression algorithm using cross_val_score \n",
    "lr_scores = []\n",
    "for i in range(10, 101, 10):\n",
    "  lr_classifier = LogisticRegression(random_state=16)\n",
    "  cvs_scores = cross_val_score(lr_classifier, X, y, cv=5)\n",
    "  lr_scores.append(round(cvs_scores.mean(),3))\n",
    "# Plotting the results of lr_scores\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot([n for n in range(10, 101, 10)], lr_scores, color = 'red')\n",
    "for i in range(1,11):\n",
    "    plt.text(i*10, lr_scores[i-1], (i*10, lr_scores[i-1]))\n",
    "plt.xticks([i for i in range(10, 101, 10)])\n",
    "plt.xlabel('Random State')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Logistic Regression scores for different N values')\n",
    "# Training the Logistic Regression classifier model with n value as 90\n",
    "lr_classifier = LogisticRegression(random_state=16)\n",
    "cvs_scores = cross_val_score(lr_classifier, X, y, cv=5)\n",
    "print(\"Logistic Regression Classifier Accuracy with random state 16 is: {}%\".format(round(cvs_scores.mean(), 4)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAUSSIAN NB ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff0e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Finding the best accuracy for GaussianNB algorithm using cross_val_score \n",
    "gnb_scores = []\n",
    "for i in range(10, 101, 10):\n",
    "  gnb_classifier = GaussianNB()\n",
    "  cvs_scores = cross_val_score(gnb_classifier, X, y, cv=5)\n",
    "  gnb_scores.append(round(cvs_scores.mean(),3))\n",
    "# Plotting the results of gnb_scores\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot([n for n in range(10, 101, 10)], gnb_scores, color = 'red')\n",
    "for i in range(1,11):\n",
    "    plt.text(i*10, gnb_scores[i-1], (i*10, gnb_scores[i-1]))\n",
    "plt.xticks([i for i in range(10, 101, 10)])\n",
    "plt.xlabel('Random State')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('GaussianNB scores for different N values')\n",
    "# Training the GaussianNB classifier model with n value as 90\n",
    "gnb_classifier = GaussianNB()\n",
    "cvs_scores = cross_val_score(gnb_classifier, X, y, cv=5)\n",
    "print(\"GaussianNB Classifier Accuracy is: {}%\".format(round(cvs_scores.mean(), 4)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT BOOSTING CLASSIFIER\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Finding the best accuracy for GradientBoostingClassifier algorithm using cross_val_score \n",
    "gbc_scores = []\n",
    "for i in range(10, 101, 10):\n",
    "  gbc_classifier = GradientBoostingClassifier(learning_rate=0.1)\n",
    "  cvs_scores = cross_val_score(gbc_classifier, X, y, cv=5)\n",
    "  gbc_scores.append(round(cvs_scores.mean(),3))\n",
    "# Plotting the results of gbc_scores\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot([n for n in range(10, 101, 10)], gbc_scores, color = 'red')\n",
    "for i in range(1,11):\n",
    "    plt.text(i*10, gbc_scores[i-1], (i*10, gbc_scores[i-1]))\n",
    "plt.xticks([i for i in range(10, 101, 10)])\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('GradientBoostingClassifier scores for different N values')\n",
    "# Training the GradientBoostingClassifier model with n value as 90\n",
    "gbc_classifier = GradientBoostingClassifier(learning_rate=0.1)\n",
    "cvs_scores = cross_val_score(gbc_classifier, X, y, cv=5)\n",
    "print(\"GradientBoostingClassifier Accuracy with learning rate 1 is: {}%\".format(round(cvs_scores.mean(), 4)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accu=max(res1,res2,res3)\n",
    "if accu==res1:\n",
    "    s='K-Neighbours Classifier\\n'\n",
    "elif accu==res2:\n",
    "    s='Decision Tree Classifier\\n'\n",
    "elif accu==res3:\n",
    "    s='Random Forest Classifier\\n'\n",
    "print('The most accurate model is the '+s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
